
#!/bin/bash

# WRKY Analysis Pipeline - Serial Version with Classification
# Author: Generated for WRKY transcription factor analysis
# Date: $(date)

# Note: Removed 'set -e' to allow script to continue even when individual samples fail

# ğŸ¯ Configuration
WORK_DIR="/share/org/YZWL/yzwl_lixg/project/98.pwrky/08.è‹”è—“ç±»"
# Updated paths for uncompressed files in separate directories
FASTA_DIR="/share/org/YZWL/yzwl_lixg/project/98.pwrky/08.è‹”è—“ç±»/01.data/fasta"
GFF_DIR="/share/org/YZWL/yzwl_lixg/project/98.pwrky/08.è‹”è—“ç±»/01.data/gff/fixed"
HMM_DB="/share/org/YZWL/yzwl_lixg/project/98.pwrky/01.data/PF03106.hmm"
CDD_DB="/share/org/YZWL/yzwl_lixg/database/ncbicdd/db/ncbicdd"
WRKY_CDD_ID="460808"
EVALUE_THRESHOLD="1e-4"

# ğŸ“ Create directories
mkdir -p "${WORK_DIR}"/{01.data/longest_pep,02.hmmsearch/{raw,clean,domain_seq,classification},03.ncbicdd/{raw,clean,domain_seq,classification},04.direct/classification,05.domain_seq,06.final_classification}

# ğŸ“ Log files
LOG_FILE="${WORK_DIR}/pipeline.log"
ERROR_SAMPLE_FILE="${WORK_DIR}/01.data/error_sample.txt"
SUMMARY_FILE="${WORK_DIR}/analysis_summary.txt"

# ğŸ• æ—¶é—´æˆ³å’Œæ—¥å¿—å‡½æ•°
get_timestamp() {
    if command -v python3 >/dev/null 2>&1; then
        python3 -c "import datetime; print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S,%f')[:-3])"
    else
        date '+%Y-%m-%d %H:%M:%S'
    fi
}

log_info() {
    local message="$1"
    local timestamp=$(get_timestamp)
    echo "${timestamp} - INFO - ${message}" | tee -a "${LOG_FILE}"
}

log_error() {
    local message="$1"
    local timestamp=$(get_timestamp)
    echo "${timestamp} - ERROR - ${message}" | tee -a "${LOG_FILE}"
}

log_warn() {
    local message="$1"
    local timestamp=$(get_timestamp)
    echo "${timestamp} - WARN - ${message}" | tee -a "${LOG_FILE}"
}

log_debug() {
    local message="$1"
    local timestamp=$(get_timestamp)
    echo "${timestamp} - DEBUG - ${message}" | tee -a "${LOG_FILE}"
}

# ğŸš€ Initialize log
log_info "ğŸ§¬ WRKY Analysis Pipeline Started - Fixed Version"
log_info "ğŸ“‚ Working directory: ${WORK_DIR}"
log_info "ğŸ”§ Script PID: $$"
log_info "ğŸ—‚ï¸ Log file: ${LOG_FILE}"
echo "" | tee -a "${LOG_FILE}"

# ğŸ§¹ Clean error file
> "${ERROR_SAMPLE_FILE}"

# ğŸ“‹ Function to extract sample names
get_samples() {
    # Look for .fa files in the fasta directory and extract sample names
    find "${FASTA_DIR}" -name "*.fa" | sed 's/.*\///; s/\.fa$//' | sort | uniq
}

# ğŸ”§ Function to extract longest transcript
extract_longest_transcript() {
    local sample="$1"
    local fa_file="${FASTA_DIR}/${sample}.fa"
    local gff_file="${GFF_DIR}/${sample}.primary.gff3"
    local output="${WORK_DIR}/01.data/longest_pep/${sample}.longest.pep.fa"
    
    log_info "ğŸ“Š Extracting longest transcript for ${sample}..."
    
    # Check if files exist
    if [[ ! -f "${fa_file}" ]]; then
        log_error "âŒ FASTA file not found: ${fa_file}"
        echo "${sample}" >> "${ERROR_SAMPLE_FILE}"
        return 1
    fi
    
    if [[ ! -f "${gff_file}" ]]; then
        log_error "âŒ GFF file not found: ${gff_file}"
        echo "${sample}" >> "${ERROR_SAMPLE_FILE}"
        return 1
    fi
    
    # Extract longest transcript (files are already uncompressed)
    if biopytools longest-mrna -g "${fa_file}" -f "${gff_file}" -o "${output}" 2>&1; then
        if [[ -s "${output}" ]]; then
            local seq_count=$(grep -c "^>" "${output}" 2>/dev/null || echo 0)
            log_info "âœ… Successfully extracted longest transcript (${seq_count} sequences)"
            return 0
        else
            log_error "âŒ Output file is empty"
            echo "${sample}" >> "${ERROR_SAMPLE_FILE}"
            return 1
        fi
    else
        log_error "âŒ Failed to extract longest transcript"
        echo "${sample}" >> "${ERROR_SAMPLE_FILE}"
        return 1
    fi
}

# ğŸ” Function to run HMM search (ORIGINAL WORKING VERSION + MINIMAL DEBUG)
run_hmm_search() {
    local sample="$1"
    local input="${WORK_DIR}/01.data/longest_pep/${sample}.longest.pep.fa"
    local output="${WORK_DIR}/02.hmmsearch/raw/${sample}.hmm.txt"
    
    log_info "ğŸ” Running HMM search for ${sample}..."
    
    # Add minimal debugging - check files exist
    if [[ ! -f "${input}" ]]; then
        log_error "âŒ Input file missing: ${input}"
        return 1
    fi
    if [[ ! -f "${HMM_DB}" ]]; then
        log_error "âŒ HMM database missing: ${HMM_DB}"
        return 1
    fi
    
    # Show the command being run (this should appear in log)
    log_info "ğŸ”§ Command: hmmsearch --domtblout ${output} --cut_tc --cpu 80 ${HMM_DB} ${input}"
    
    # Original working logic with error capture
    local error_log="${WORK_DIR}/02.hmmsearch/raw/${sample}.hmm.err"
    if hmmsearch --domtblout "${output}" --cut_tc --cpu 80 "${HMM_DB}" "${input}" > /dev/null 2>"${error_log}"; then
        if [[ -s "${output}" ]]; then
            log_info "âœ… HMM search completed successfully"
            return 0
        else
            log_warn "âš ï¸ No HMM results found (empty output)"
            return 1
        fi
    else
        local exit_code=$?
        log_error "âŒ HMM search failed (exit code: ${exit_code})"
        if [[ -s "${error_log}" ]]; then
            log_error "âŒ Error details:"
            head -5 "${error_log}" | while read line; do
                log_error "   ${line}"
            done
        fi
        return 1
    fi
}

# ğŸ§¹ Function to clean HMM results
clean_hmm_results() {
    local sample="$1"
    local input="${WORK_DIR}/02.hmmsearch/raw/${sample}.hmm.txt"
    local output="${WORK_DIR}/02.hmmsearch/clean/${sample}.hmm.clean.txt"
    
    log_info "ğŸ§¹ Cleaning HMM results for ${sample}..."
    
    # Extract useful information: protein_id, ali_from, ali_to, evalue
    grep -v "^#" "${input}" | awk '{
        if (NF >= 22) {
            protein_id = $1
            evalue = $7
            ali_from = $18
            ali_to = $19
            print protein_id "\t" ali_from "\t" ali_to "\t" evalue
        }
    }' > "${output}"
    
    local count=$(wc -l < "${output}")
    log_info "ğŸ“Š Found ${count} HMM domains"
}

# ğŸ§¬ Function to extract HMM domain sequences
extract_hmm_domains() {
    local sample="$1"
    local clean_file="${WORK_DIR}/02.hmmsearch/clean/${sample}.hmm.clean.txt"
    local pep_file="${WORK_DIR}/01.data/longest_pep/${sample}.longest.pep.fa"
    local output="${WORK_DIR}/02.hmmsearch/domain_seq/${sample}.hmm.domain.fa"
    
    log_info "ğŸ§¬ Extracting HMM domain sequences for ${sample}..."
    
    local python_result=$(python3 << EOF 2>&1
import sys
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord

try:
    # Read protein sequences
    pep_seqs = {}
    for record in SeqIO.parse("${pep_file}", "fasta"):
        pep_seqs[record.id] = str(record.seq)

    # Extract domains
    domain_seqs = []
    with open("${clean_file}", "r") as f:
        for line in f:
            if line.strip():
                parts = line.strip().split("\t")
                if len(parts) >= 4:
                    protein_id, start, end, evalue = parts[:4]
                    start, end = int(start) - 1, int(end)  # Convert to 0-based
                    
                    if protein_id in pep_seqs:
                        domain_seq = pep_seqs[protein_id][start:end]
                        domain_id = f"{protein_id}_hmm_{start+1}_{end}"
                        domain_record = SeqRecord(Seq(domain_seq), id=domain_id, 
                                                description=f"HMM_domain evalue={evalue}")
                        domain_seqs.append(domain_record)

    # Write domain sequences
    if domain_seqs:
        SeqIO.write(domain_seqs, "${output}", "fasta")
        print(f"SUCCESS: Extracted {len(domain_seqs)} HMM domain sequences")
    else:
        with open("${output}", "w") as f:
            pass  # Create empty file
        print("WARNING: No HMM domain sequences found")
        
except Exception as e:
    print(f"ERROR: {e}")
    sys.exit(1)
EOF
)
    
    if [[ $? -eq 0 ]]; then
        log_info "${python_result}"
    else
        log_error "${python_result}"
    fi
}

# ğŸ”¬ Function for WRKY subfamily classification
classify_wrky_subfamilies() {
    local sample="$1"
    local input="${WORK_DIR}/02.hmmsearch/domain_seq/${sample}.hmm.domain.fa"
    local output="${WORK_DIR}/02.hmmsearch/classification/${sample}.wrky_classification.txt"
    
    log_info "ğŸ”¬ Classifying WRKY subfamilies for ${sample}..."
    
    # Check if input file exists and has content
    if [[ ! -f "${input}" ]] || [[ ! -s "${input}" ]]; then
        log_warn "âš ï¸ No HMM domain sequences available for classification"
        echo -e "Gene_ID\tGroup\tSubgroup\tConfidence\tNote" > "${output}"
        echo -e "No_domains\tN/A\tN/A\tN/A\tNo HMM domain sequences found" >> "${output}"
        return 1
    fi
    
    local python_result=$(python3 << EOF 2>&1
import re
from typing import Dict, List, Tuple
from collections import defaultdict

def quick_wrky_classifier(fasta_file: str) -> Dict:
    """
    å¿«é€ŸWRKYåˆ†ç±»å™¨ - ä¿å®ˆä½†å‡†ç¡®
    """
    # è¯»å–FASTAæ–‡ä»¶
    sequences = read_fasta_file(fasta_file)
    
    # æŒ‰åŸºå› IDåˆ†ç»„
    gene_groups = group_sequences_by_gene(sequences)
    
    results = {}
    for gene_id, domains in gene_groups.items():
        classification = classify_gene_quick(domains)
        # å¤„ç†Group Içš„ç‰¹æ®Šæƒ…å†µ
        if classification['group'] == 'I' and 'domains' in classification:
            # ä¸ºæ¯ä¸ªåŸŸåˆ›å»ºå•ç‹¬çš„è®°å½•
            for i, domain_info in enumerate(classification['domains']):
                domain_gene_id = f"{gene_id}_domain_{i+1}"
                results[domain_gene_id] = {
                    'group': 'I',
                    'subgroup': domain_info['subgroup'],
                    'confidence': domain_info['confidence'],
                    'reason': classification.get('reason', '-')
                }
        else:
            results[gene_id] = classification
    
    return results

def read_fasta_file(file_path: str) -> List[Tuple[str, str]]:
    """è¯»å–FASTAæ–‡ä»¶"""
    sequences = []
    try:
        with open(file_path, 'r') as f:
            header = None
            sequence = []
            for line in f:
                line = line.strip()
                if line.startswith('>'):
                    if header is not None:
                        sequences.append((header, ''.join(sequence)))
                    header = line
                    sequence = []
                else:
                    sequence.append(line)
            # æ·»åŠ æœ€åä¸€æ¡åºåˆ—
            if header is not None:
                sequences.append((header, ''.join(sequence)))
    except Exception as e:
        print(f"Error reading FASTA file: {e}")
    return sequences

def group_sequences_by_gene(sequences: List[Tuple[str, str]]) -> Dict:
    """æŒ‰åŸºå› IDåˆ†ç»„åºåˆ—"""
    gene_groups = defaultdict(list)
    
    for header, seq in sequences:
        gene_id = extract_gene_id(header)
        position = extract_position(header)
        gene_groups[gene_id].append({
            'header': header,
            'sequence': seq,
            'position': position
        })
    
    # æŒ‰ä½ç½®æ’åºæ¯ä¸ªåŸºå› çš„ç»“æ„åŸŸ
    for gene_id in gene_groups:
        gene_groups[gene_id].sort(key=lambda x: x['position'])
    
    return dict(gene_groups)

def extract_gene_id(header: str) -> str:
    """ä»headeræå–åŸºå› ID"""
    return header.split('_hmm_')[0].replace('>', '')

def extract_position(header: str) -> int:
    """ä»headeræå–ä½ç½®ä¿¡æ¯"""
    match = re.search(r'_hmm_(\d+)_', header)
    return int(match.group(1)) if match else 0

def classify_gene_quick(domains: List[Dict]) -> Dict:
    """
    å¿«é€ŸåŸºå› åˆ†ç±» - åŸºäºæ˜ç¡®ç‰¹å¾
    """
    domain_count = len(domains)
    
    if domain_count == 2:
        # Group I: ä¸¤ä¸ªç»“æ„åŸŸï¼Œè¿”å›ä¸¤ä¸ªåˆ†ç±»ç»“æœ
        return classify_group_i(domains)
    elif domain_count == 1:
        # Group II/III: å•ä¸ªç»“æ„åŸŸ
        return classify_single_domain(domains[0])
    else:
        return {
            'group': 'other',
            'subgroup': '-',
            'reason': f'unusual_domain_count_{domain_count}',
            'confidence': 'low'
        }

def classify_group_i(domains: List[Dict]) -> Dict:
    """
    Group I åˆ†ç±» - è¿”å›ä¸¤ä¸ªåŸŸçš„åˆ†ç±»ç»“æœ
    """
    n_term = domains[0]['sequence']
    c_term = domains[1]['sequence']
    
    # æ£€æŸ¥å…³é”®ç‰¹å¾
    n_wrky = extract_wrky_start(n_term)
    c_wrky = extract_wrky_start(c_term)
    
    # ç®€å•æ˜ç¡®çš„è§„åˆ™
    if n_wrky == 'N' and c_wrky == 'R':
        # è¿›ä¸€æ­¥éªŒè¯é”ŒæŒ‡
        n_zinc = check_c2h2_zinc_finger(n_term)
        c_zinc = check_c2h2_zinc_finger(c_term)
        
        if n_zinc and c_zinc:
            return {
                'group': 'I',
                'domains': [
                    {
                        'subgroup': 'I_NT',
                        'confidence': 'high',
                        'position': domains[0]['position']
                    },
                    {
                        'subgroup': 'I_CT',
                        'confidence': 'high',
                        'position': domains[1]['position']
                    }
                ],
                'reason': '-'
            }
    
    return {
        'group': 'other',
        'subgroup': '-',
        'reason': f'group_i_unclear_n={n_wrky}_c={c_wrky}',
        'confidence': 'low'
    }

def classify_single_domain(domain: Dict) -> Dict:
    """
    å•ç»“æ„åŸŸåˆ†ç±» - åŸºäºæ˜ç¡®ç‰¹å¾
    """
    seq = domain['sequence']
    wrky_start = extract_wrky_start(seq)
    
    # æ£€æŸ¥é”ŒæŒ‡ç±»å‹
    has_c2h2 = check_c2h2_zinc_finger(seq)
    has_c2hc = check_c2hc_zinc_finger(seq)
    
    if not (has_c2h2 or has_c2hc):
        return {
            'group': 'other',
            'subgroup': '-',
            'reason': 'no_clear_zinc_finger',
            'confidence': 'low'
        }
    
    # Group III: C2HCé”ŒæŒ‡
    if has_c2hc:
        if wrky_start == 'S':
            return {'group': 'III', 'subgroup': 'IIIa', 'confidence': 'high', 'reason': '-'}
        elif wrky_start == 'Q':
            return {'group': 'III', 'subgroup': 'IIIb', 'confidence': 'high', 'reason': '-'}
        else:
            return {
                'group': 'other', 
                'subgroup': '-',
                'reason': f'group_iii_unclear_start={wrky_start}',
                'confidence': 'low'
            }
    
    # Group II: C2H2é”ŒæŒ‡
    if has_c2h2:
        return classify_group_ii(seq, wrky_start)
    
    return {
        'group': 'other',
        'subgroup': '-',
        'reason': 'zinc_finger_ambiguous',
        'confidence': 'low'
    }

def classify_group_ii(seq: str, wrky_start: str) -> Dict:
    """
    Group II è¯¦ç»†åˆ†ç±» - åŸºäºæ˜ç¡®æ¨¡å¼
    """
    # IIa/IIb: ç‰¹æ®ŠåŸºåºè¯†åˆ«
    if wrky_start == 'Q':
        if 'CPVKKKV' in seq:
            return {'group': 'II', 'subgroup': 'IIa', 'confidence': 'high', 'reason': '-'}
        elif 'CPVRKQV' in seq:
            return {'group': 'II', 'subgroup': 'IIb', 'confidence': 'high', 'reason': '-'}
        else:
            return {
                'group': 'other',
                'subgroup': '-',
                'reason': 'group_ii_q_no_special_motif',
                'confidence': 'low'
            }
    
    # IIc: Rå¼€å¤´ + ç‰¹å®šç‰¹å¾
    elif wrky_start == 'R':
        if 'RSYYRC' in seq:  # vs RSYYKC in Group I
            return {'group': 'II', 'subgroup': 'IIc', 'confidence': 'medium', 'reason': '-'}
        else:
            return {
                'group': 'other',
                'subgroup': '-',
                'reason': 'group_ii_r_unclear',
                'confidence': 'low'
            }
    
    # IId: Så¼€å¤´
    elif wrky_start == 'S':
        if check_x5_spacing(seq):
            return {'group': 'II', 'subgroup': 'IId', 'confidence': 'medium', 'reason': '-'}
        else:
            return {
                'group': 'other',
                'subgroup': '-',
                'reason': 'group_ii_s_unclear_spacing',
                'confidence': 'low'
            }
    
    # IIe: Aå¼€å¤´
    elif wrky_start == 'A':
        if check_x5_spacing(seq):
            return {'group': 'II', 'subgroup': 'IIe', 'confidence': 'medium', 'reason': '-'}
        else:
            return {
                'group': 'other',
                'subgroup': '-',
                'reason': 'group_ii_a_unclear_spacing', 
                'confidence': 'low'
            }
    
    else:
        return {
            'group': 'other',
            'subgroup': '-',
            'reason': f'group_ii_unknown_start={wrky_start}',
            'confidence': 'low'
        }

# è¾…åŠ©å‡½æ•°
def extract_wrky_start(sequence: str) -> str:
    """æå–WRKYå‰çš„èµ·å§‹æ°¨åŸºé…¸"""
    match = re.search(r'([NRQSAW])WRKYGQK', sequence)
    return match.group(1) if match else 'unknown'

def check_c2h2_zinc_finger(sequence: str) -> bool:
    """æ£€æŸ¥C2H2é”ŒæŒ‡æ¨¡å¼"""
    pattern = r'C.{4,5}C.{20,25}H.H'
    return bool(re.search(pattern, sequence))

def check_c2hc_zinc_finger(sequence: str) -> bool:
    """æ£€æŸ¥C2HCé”ŒæŒ‡æ¨¡å¼"""
    pattern = r'C.{6,8}C.{20,30}H.C'
    return bool(re.search(pattern, sequence))

def check_x5_spacing(sequence: str) -> bool:
    """æ£€æŸ¥X5é—´éš”æ¨¡å¼ (IId/IIeç‰¹å¾)"""
    pattern = r'C.{5}C.{20,25}H'
    return bool(re.search(pattern, sequence))

# ä¸»å¤„ç†å‡½æ•°
def process_hmm_results(file_path: str, output_path: str) -> None:
    """
    å¤„ç†hmmsearchç»“æœå¹¶è¾“å‡ºåˆ†ç±»
    """
    try:
        results = quick_wrky_classifier(file_path)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_genes = len(results)
        group_counts = defaultdict(int)
        confidence_counts = defaultdict(int)
        
        # å†™å…¥ç»“æœæ–‡ä»¶
        with open(output_path, 'w') as f:
            f.write("Gene_ID\tGroup\tSubgroup\tConfidence\tNote\n")
            
            for gene_id, classification in results.items():
                group = classification['group']
                subgroup = classification.get('subgroup', '-')
                confidence = classification['confidence']
                reason = classification.get('reason', '-')
                
                f.write(f"{gene_id}\t{group}\t{subgroup}\t{confidence}\t{reason}\n")
                
                # ç»Ÿè®¡
                if group in ['I', 'II', 'III']:
                    group_counts[subgroup] += 1
                else:
                    group_counts['other'] += 1
                confidence_counts[confidence] += 1
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"SUCCESS: Classification completed: {total_genes} genes processed")
        print("Group distribution:")
        for group, count in sorted(group_counts.items()):
            print(f"  {group}: {count}")
        print("Confidence distribution:")
        for conf, count in sorted(confidence_counts.items()):
            print(f"  {conf}: {count}")
            
    except Exception as e:
        print(f"ERROR: WRKY classification failed: {e}")

# æ‰§è¡Œåˆ†ç±»
process_hmm_results("${input}", "${output}")
EOF
)
    log_info "${python_result}"
}

# ğŸ” Function to run CDD search (ORIGINAL WORKING VERSION + MINIMAL DEBUG + PERIOD HANDLING)
run_cdd_search() {
    local sample="$1"
    local input="${WORK_DIR}/01.data/longest_pep/${sample}.longest.pep.fa"
    local output="${WORK_DIR}/03.ncbicdd/raw/${sample}.cdd.txt"
    local temp_input="${WORK_DIR}/03.ncbicdd/raw/${sample}.temp.fa"
    
    log_info "ğŸ” Running CDD search for ${sample}..."
    
    # Add minimal debugging - check files exist
    if [[ ! -f "${input}" ]]; then
        log_error "âŒ Input file missing: ${input}"
        return 1
    fi
    
    # Create a cleaned temporary file - replace periods with X (unknown amino acid)
    log_info "ğŸ”§ Creating temporary file with periods replaced by X..."
    
    local clean_result=$(python3 << EOF 2>&1
try:
    from Bio import SeqIO
    from Bio.Seq import Seq
    from Bio.SeqRecord import SeqRecord
    
    cleaned_sequences = []
    period_count = 0
    total_sequences = 0
    
    # Read and clean sequences
    for record in SeqIO.parse("${input}", "fasta"):
        total_sequences += 1
        original_seq = str(record.seq)
        
        # Count periods in this sequence
        seq_periods = original_seq.count('.')
        if seq_periods > 0:
            period_count += seq_periods
            # Replace periods with X (unknown amino acid)
            cleaned_seq = original_seq.replace('.', 'X')
            cleaned_record = SeqRecord(Seq(cleaned_seq), id=record.id, description=record.description)
            cleaned_sequences.append(cleaned_record)
        else:
            # No periods, keep original
            cleaned_sequences.append(record)
    
    # Write cleaned sequences to temporary file
    SeqIO.write(cleaned_sequences, "${temp_input}", "fasta")
    print(f"SUCCESS: Cleaned {total_sequences} sequences, replaced {period_count} periods with X")

except Exception as e:
    print(f"ERROR: Failed to create temporary file: {e}")
    exit(1)
EOF
)
    
    if [[ $? -ne 0 ]]; then
        log_error "âŒ Failed to create cleaned temporary file"
        log_error "${clean_result}"
        return 1
    fi
    
    log_info "${clean_result}"
    
    # Show the command being run (using temporary file)
    log_info "ğŸ”§ Command: rpsblast -query ${temp_input} -outfmt 6 -evalue ${EVALUE_THRESHOLD} -db ${CDD_DB} -out ${output} -num_threads 80"
    
    # Run CDD search with cleaned temporary file
    local error_log="${WORK_DIR}/03.ncbicdd/raw/${sample}.cdd.err"
    if rpsblast -query "${temp_input}" -outfmt 6 -evalue "${EVALUE_THRESHOLD}" \
                -db "${CDD_DB}" -out "${output}" -num_threads 80 > /dev/null 2>"${error_log}"; then
        # Clean up temporary file
        rm -f "${temp_input}"
        
        if [[ -s "${output}" ]]; then
            log_info "âœ… CDD search completed successfully"
            return 0
        else
            log_warn "âš ï¸ No CDD results found (empty output)"
            return 1
        fi
    else
        local exit_code=$?
        # Clean up temporary file even on failure
        rm -f "${temp_input}"
        
        log_error "âŒ CDD search failed (exit code: ${exit_code})"
        if [[ -s "${error_log}" ]]; then
            log_error "âŒ Error details:"
            head -5 "${error_log}" | while read line; do
                log_error "   ${line}"
            done
        fi
        return 1
    fi
}

# ğŸ§¹ Function to clean CDD results
clean_cdd_results() {
    local sample="$1"
    local input="${WORK_DIR}/03.ncbicdd/raw/${sample}.cdd.txt"
    local output="${WORK_DIR}/03.ncbicdd/clean/${sample}.cdd.clean.txt"
    
    log_info "ğŸ§¹ Cleaning CDD results for ${sample}..."
    
    # Filter for WRKY CDD ID (note: CDD results have "CDD:" prefix)
    # Extract: protein_id, query_start, query_end, evalue
    awk -v cdd_id="CDD:${WRKY_CDD_ID}" '$2 == cdd_id {
        print $1 "\t" $7 "\t" $8 "\t" $11
    }' "${input}" > "${output}"
    
    local count=$(wc -l < "${output}")
    log_info "ğŸ“Š Found ${count} CDD domains (CDD:${WRKY_CDD_ID})"
}

# ğŸ§¬ Function to extract CDD domain sequences
extract_cdd_domains() {
    local sample="$1"
    local clean_file="${WORK_DIR}/03.ncbicdd/clean/${sample}.cdd.clean.txt"
    local pep_file="${WORK_DIR}/01.data/longest_pep/${sample}.longest.pep.fa"
    local output="${WORK_DIR}/03.ncbicdd/domain_seq/${sample}.ncbicdd.domain.fa"
    
    log_info "ğŸ§¬ Extracting CDD domain sequences for ${sample}..."
    
    local python_result=$(python3 << EOF 2>&1
import sys
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord

try:
    # Read protein sequences
    pep_seqs = {}
    for record in SeqIO.parse("${pep_file}", "fasta"):
        pep_seqs[record.id] = str(record.seq)

    # Extract domains
    domain_seqs = []
    with open("${clean_file}", "r") as f:
        for line in f:
            if line.strip():
                parts = line.strip().split("\t")
                if len(parts) >= 4:
                    protein_id, start, end, evalue = parts[:4]
                    start, end = int(start) - 1, int(end)  # Convert to 0-based
                    
                    if protein_id in pep_seqs:
                        domain_seq = pep_seqs[protein_id][start:end]
                        domain_id = f"{protein_id}_cdd_{start+1}_{end}"
                        domain_record = SeqRecord(Seq(domain_seq), id=domain_id, 
                                                description=f"CDD_domain evalue={evalue}")
                        domain_seqs.append(domain_record)

    # Write domain sequences
    if domain_seqs:
        SeqIO.write(domain_seqs, "${output}", "fasta")
        print(f"SUCCESS: Extracted {len(domain_seqs)} CDD domain sequences")
    else:
        with open("${output}", "w") as f:
            pass  # Create empty file
        print("WARNING: No CDD domain sequences found")
        
except Exception as e:
    print(f"ERROR: {e}")
    sys.exit(1)
EOF
)
    
    if [[ $? -eq 0 ]]; then
        log_info "${python_result}"
    else
        log_error "${python_result}"
    fi
}

# ğŸ”„ Function to integrate results
integrate_results() {
    local sample="$1"
    local hmm_file="${WORK_DIR}/02.hmmsearch/clean/${sample}.hmm.clean.txt"
    local cdd_file="${WORK_DIR}/03.ncbicdd/clean/${sample}.cdd.clean.txt"
    local hmm_seq="${WORK_DIR}/02.hmmsearch/domain_seq/${sample}.hmm.domain.fa"
    local cdd_seq="${WORK_DIR}/03.ncbicdd/domain_seq/${sample}.ncbicdd.domain.fa"
    
    log_info "ğŸ”„ Integrating results for ${sample}..."
    
    local python_result=$(python3 << EOF 2>&1
import os
from collections import defaultdict
import shutil

try:
    # Read HMM results
    hmm_domains = {}
    if os.path.exists("${hmm_file}") and os.path.getsize("${hmm_file}") > 0:
        with open("${hmm_file}", "r") as f:
            for line in f:
                if line.strip():
                    parts = line.strip().split("\t")
                    if len(parts) >= 4:
                        protein_id, start, end, evalue = parts[:4]
                        hmm_domains[protein_id] = hmm_domains.get(protein_id, [])
                        hmm_domains[protein_id].append((int(start), int(end)))

    # Read CDD results
    cdd_domains = {}
    if os.path.exists("${cdd_file}") and os.path.getsize("${cdd_file}") > 0:
        with open("${cdd_file}", "r") as f:
            for line in f:
                if line.strip():
                    parts = line.strip().split("\t")
                    if len(parts) >= 4:
                        protein_id, start, end, evalue = parts[:4]
                        cdd_domains[protein_id] = cdd_domains.get(protein_id, [])
                        cdd_domains[protein_id].append((int(start), int(end)))

    # Compare and integrate
    final_output = "${WORK_DIR}/05.domain_seq/${sample}.final.domain.fa"

    if os.path.exists("${hmm_seq}") and os.path.exists("${cdd_seq}"):
        # Combine both files
        with open(final_output, "w") as out:
            with open("${hmm_seq}", "r") as f:
                out.write(f.read())
            with open("${cdd_seq}", "r") as f:
                out.write(f.read())
        print("SUCCESS: Combined HMM and CDD results")
    elif os.path.exists("${hmm_seq}"):
        shutil.copy("${hmm_seq}", final_output)
        print("SUCCESS: Used HMM results only")
    elif os.path.exists("${cdd_seq}"):
        shutil.copy("${cdd_seq}", final_output)
        print("SUCCESS: Used CDD results only")
    else:
        with open(final_output, "w") as f:
            pass  # Create empty file
        print("WARNING: No domain results available")
        
except Exception as e:
    print(f"ERROR: {e}")
    sys.exit(1)
EOF
)
    
    if [[ $? -eq 0 ]]; then
        log_info "${python_result}"
    else
        log_error "${python_result}"
    fi
}

# ğŸ”¤ Function to search WRKY directly in sequences
search_wrky_direct() {
    local sample="$1"
    local input="${WORK_DIR}/01.data/longest_pep/${sample}.longest.pep.fa"
    local output="${WORK_DIR}/04.direct/${sample}.wrky_direct.fa"
    
    log_info "ğŸ”¤ Searching WRKY directly in sequences for ${sample}..."
    
    local python_result=$(python3 << EOF 2>&1
from Bio import SeqIO
import re

try:
    wrky_sequences = []
    for record in SeqIO.parse("${input}", "fasta"):
        # Search for WRKY in the protein sequence
        if re.search(r'WRKY', str(record.seq), re.IGNORECASE):
            wrky_sequences.append(record)

    if wrky_sequences:
        SeqIO.write(wrky_sequences, "${output}", "fasta")
        print(f"SUCCESS: Found {len(wrky_sequences)} sequences containing WRKY")
    else:
        with open("${output}", "w") as f:
            pass  # Create empty file
        print("WARNING: No sequences containing WRKY found")
        
except Exception as e:
    print(f"ERROR: {e}")
    sys.exit(1)
EOF
)
    
    if [[ $? -eq 0 ]]; then
        log_info "${python_result}"
        return 0
    else
        log_error "${python_result}"
        return 1
    fi
}

# ğŸ”¬ Function to generate final WRKY classification summary
generate_final_classification() {
    local sample="$1"
    log_info "ğŸ”¬ Generating final WRKY classification for ${sample}..."
    
    local hmm_class="${WORK_DIR}/02.hmmsearch/classification/${sample}.wrky_classification.txt"
    local cdd_seq="${WORK_DIR}/03.ncbicdd/domain_seq/${sample}.ncbicdd.domain.fa"
    local direct_seq="${WORK_DIR}/04.direct/${sample}.wrky_direct.fa"
    local final_class="${WORK_DIR}/06.final_classification/${sample}.final_wrky_summary.txt"
    
    local python_result=$(python3 << EOF 2>&1
import os
from collections import defaultdict
import re

def extract_gene_id_from_header(header):
    """ä»fasta headerä¸­æå–åŸºå› ID"""
    gene_id = header.replace('>', '').split()[0]
    gene_id = re.split(r'_(?:hmm|cdd|domain)_', gene_id)[0]
    return gene_id

def read_fasta_gene_ids(file_path):
    """è¯»å–FASTAæ–‡ä»¶å¹¶è¿”å›åŸºå› IDé›†åˆ"""
    gene_ids = set()
    if not os.path.exists(file_path) or not os.path.getsize(file_path):
        return gene_ids
    
    try:
        with open(file_path, 'r') as f:
            for line in f:
                if line.startswith('>'):
                    gene_id = extract_gene_id_from_header(line.strip())
                    gene_ids.add(gene_id)
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
    
    return gene_ids

try:
    # è¯»å–HMMåˆ†ç±»ç»“æœ
    hmm_classified = {}
    if os.path.exists("${hmm_class}") and os.path.getsize("${hmm_class}") > 0:
        with open("${hmm_class}", 'r') as f:
            next(f)  # è·³è¿‡header
            for line in f:
                if line.strip() and not line.startswith('#'):
                    parts = line.strip().split('\t')
                    if len(parts) >= 5 and parts[0] != 'No_domains':
                        gene_id, group, subgroup, confidence, note = parts[:5]
                        # å¤„ç†Group Içš„ç‰¹æ®Šæƒ…å†µ
                        base_gene_id = re.split(r'_domain_', gene_id)[0]
                        hmm_classified[base_gene_id] = {
                            'group': group,
                            'subgroup': subgroup,
                            'confidence': confidence,
                            'method': 'HMM'
                        }
    
    # è¯»å–CDDåºåˆ—åŸºå› ID
    cdd_genes = read_fasta_gene_ids("${cdd_seq}")
    
    # è¯»å–Directæœç´¢ç»“æœåŸºå› ID
    direct_genes = read_fasta_gene_ids("${direct_seq}")
    
    # è·å–æ‰€æœ‰åŸºå› ID
    hmm_genes = set(hmm_classified.keys())
    all_genes = hmm_genes | cdd_genes | direct_genes
    
    # ç”Ÿæˆæœ€ç»ˆæ±‡æ€»
    stats = {
        'total_wrky_genes': len(all_genes),
        'hmm_classified': len(hmm_genes),
        'cdd_found': len(cdd_genes),
        'direct_found': len(direct_genes),
        'both_hmm_direct': len(hmm_genes & direct_genes),
        'both_cdd_direct': len(cdd_genes & direct_genes),
        'both_hmm_cdd': len(hmm_genes & cdd_genes),
        'all_three': len(hmm_genes & cdd_genes & direct_genes),
        'direct_only': len(direct_genes - hmm_genes - cdd_genes)
    }
    
    # åˆ†ç»„ç»Ÿè®¡
    group_stats = defaultdict(int)
    for gene_data in hmm_classified.values():
        if gene_data['group'] in ['I', 'II', 'III']:
            group_stats[gene_data['subgroup']] += 1
        else:
            group_stats['other'] += 1
    
    # å†™å…¥æœ€ç»ˆåˆ†ç±»æ–‡ä»¶
    with open("${final_class}", 'w') as f:
        f.write("# WRKY Gene Classification Summary for ${sample}\n")
        f.write("# Generated by WRKY Analysis Pipeline\n")
        f.write("#\n")
        f.write("Gene_ID\tGroup\tSubgroup\tConfidence\tMethod\tDirect_Search\n")
        
        for gene_id in sorted(all_genes):
            if gene_id in hmm_classified:
                gene_data = hmm_classified[gene_id]
                direct_found = "Yes" if gene_id in direct_genes else "No"
                subgroup = gene_data['subgroup']
                
                f.write(f"{gene_id}\t{gene_data['group']}\t{subgroup}\t"
                       f"{gene_data['confidence']}\t{gene_data['method']}\t{direct_found}\n")
            else:
                f.write(f"{gene_id}\tNA\tNA\tNA\tDirect_only\tYes\n")
        
        f.write("\n# Statistics Summary:\n")
        f.write(f"# Total WRKY genes found: {stats['total_wrky_genes']}\n")
        f.write(f"# HMM classified: {stats['hmm_classified']}\n")
        f.write(f"# CDD domain found: {stats['cdd_found']}\n")
        f.write(f"# Direct search found: {stats['direct_found']}\n")
        f.write(f"# HMM + Direct: {stats['both_hmm_direct']}\n")
        f.write(f"# CDD + Direct: {stats['both_cdd_direct']}\n")
        f.write(f"# HMM + CDD: {stats['both_hmm_cdd']}\n")
        f.write(f"# All three methods: {stats['all_three']}\n")
        f.write(f"# Direct only: {stats['direct_only']}\n")
        f.write("\n# Group Distribution:\n")
        for group, count in sorted(group_stats.items()):
            f.write(f"# {group}: {count}\n")
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"SUCCESS: Final classification summary:")
    print(f"  Total WRKY genes: {stats['total_wrky_genes']}")
    print(f"  HMM classified: {stats['hmm_classified']}")
    print(f"  CDD domain found: {stats['cdd_found']}")
    print(f"  Direct search found: {stats['direct_found']}")
    print(f"  HMM + Direct: {stats['both_hmm_direct']}")
    print(f"  CDD + Direct: {stats['both_cdd_direct']}")
    print(f"  HMM + CDD: {stats['both_hmm_cdd']}")
    print(f"  All three methods: {stats['all_three']}")
    print(f"  Direct only: {stats['direct_only']}")
    if group_stats:
        print(f"  Group distribution: {dict(group_stats)}")

except Exception as e:
    print(f"ERROR: Final classification failed: {e}")
    sys.exit(1)
EOF
)
    
    if [[ $? -eq 0 ]]; then
        log_info "${python_result}"
        return 0
    else
        log_error "${python_result}"
        return 1
    fi
}

# ğŸ“Š Function to process single sample
process_sample() {
    local sample="$1"
    log_info ""
    log_info "ğŸ§¬ Processing sample: ${sample}"
    log_info "========================================"
    
    # Step 1: Extract longest transcript - this is critical, if it fails, skip the sample
    if ! extract_longest_transcript "${sample}"; then
        log_error "âŒ Skipping ${sample} due to extraction error"
        return 1
    fi
    
    # Step 2: HMM search and classification - continue even if this fails
    local hmm_success=false
    if run_hmm_search "${sample}"; then
        clean_hmm_results "${sample}" && hmm_success=true
        extract_hmm_domains "${sample}"
        classify_wrky_subfamilies "${sample}"
        log_info "âœ… HMM analysis completed for ${sample}"
    else
        log_warn "âš ï¸ HMM analysis failed for ${sample}, continuing with other methods"
    fi
    
    # Step 3: CDD search - continue even if this fails  
    local cdd_success=false
    if run_cdd_search "${sample}"; then
        clean_cdd_results "${sample}" && cdd_success=true
        extract_cdd_domains "${sample}"
        log_info "âœ… CDD analysis completed for ${sample}"
    else
        log_warn "âš ï¸ CDD analysis failed for ${sample}, continuing with other methods"
    fi
    
    # Step 4: Integrate results - only if we have some results
    if [[ "$hmm_success" == true ]] || [[ "$cdd_success" == true ]]; then
        integrate_results "${sample}" || log_warn "âš ï¸ Result integration had issues for ${sample}"
    else
        log_warn "âš ï¸ No HMM or CDD results to integrate for ${sample}"
    fi
    
    # Step 5: Direct WRKY search - this should always work if we have the protein file
    if search_wrky_direct "${sample}"; then
        log_info "âœ… Direct WRKY search completed for ${sample}"
    else
        log_warn "âš ï¸ Direct WRKY search failed for ${sample}"
    fi
    
    # Step 6: Generate final classification summary
    if generate_final_classification "${sample}"; then
        log_info "âœ… Final classification generated for ${sample}"
    else
        log_warn "âš ï¸ Final classification failed for ${sample}"
    fi
    
    log_info "âœ… Completed processing ${sample} (some steps may have failed)"
    log_info "========================================"
    return 0  # Always return success if we got past the initial extraction step
}

# åœ¨è„šæœ¬å¼€å¤´æ·»åŠ å®‰å…¨çš„ç®—æœ¯è¿ç®—å‡½æ•°
safe_add() {
    local var1="$1"
    local var2="$2"
    
    # æ¸…ç†å˜é‡ï¼Œç§»é™¤ç©ºæ ¼å’Œéæ•°å­—å­—ç¬¦
    var1=$(echo "$var1" | tr -d ' ' | grep -o '[0-9]*' | head -1)
    var2=$(echo "$var2" | tr -d ' ' | grep -o '[0-9]*' | head -1)
    
    # å¦‚æœä¸ºç©ºåˆ™è®¾ä¸º0
    var1=${var1:-0}
    var2=${var2:-0}
    
    # éªŒè¯æ˜¯å¦ä¸ºæ•°å­—
    if ! [[ "$var1" =~ ^[0-9]+$ ]]; then
        var1=0
    fi
    if ! [[ "$var2" =~ ^[0-9]+$ ]]; then
        var2=0
    fi
    
    echo $((var1 + var2))
}

# ğŸ“ˆ Function to generate summary
generate_summary() {
    log_info ""
    log_info "ğŸ“ˆ Generating analysis summary..."
    
    {
        echo "ğŸ§¬ WRKY Analysis Summary"
        echo "======================="
        echo "ğŸ“… Analysis completed at: $(date)"
        echo ""
        
        echo "ğŸ“Š Sample Processing Results:"
        echo "----------------------------"
        
        local total_samples=0
        local successful_samples=0
        local error_samples=0
        
        if [[ -f "${ERROR_SAMPLE_FILE}" ]]; then
            error_samples=$(wc -l < "${ERROR_SAMPLE_FILE}" 2>/dev/null || echo 0)
        fi
        
        for sample in $(get_samples); do
            total_samples=$((total_samples + 1))
            if grep -q "${sample}" "${ERROR_SAMPLE_FILE}" 2>/dev/null; then
                echo "âŒ ${sample}: Failed in transcript extraction"
            else
                successful_samples=$((successful_samples + 1))
                
                # Count results for each step
                local hmm_count=0
                local cdd_count=0
                local direct_count=0
                local final_count=0
                local classified_count=0
                
                [[ -f "${WORK_DIR}/02.hmmsearch/clean/${sample}.hmm.clean.txt" ]] && \
                    hmm_count=$(wc -l < "${WORK_DIR}/02.hmmsearch/clean/${sample}.hmm.clean.txt" 2>/dev/null || echo 0)
                
                [[ -f "${WORK_DIR}/03.ncbicdd/clean/${sample}.cdd.clean.txt" ]] && \
                    cdd_count=$(wc -l < "${WORK_DIR}/03.ncbicdd/clean/${sample}.cdd.clean.txt" 2>/dev/null || echo 0)
                
                [[ -f "${WORK_DIR}/04.direct/${sample}.wrky_direct.fa" ]] && \
                    direct_count=$(grep -c "^>" "${WORK_DIR}/04.direct/${sample}.wrky_direct.fa" 2>/dev/null || echo 0)
                
                [[ -f "${WORK_DIR}/05.domain_seq/${sample}.final.domain.fa" ]] && \
                    final_count=$(grep -c "^>" "${WORK_DIR}/05.domain_seq/${sample}.final.domain.fa" 2>/dev/null || echo 0)
                
                [[ -f "${WORK_DIR}/06.final_classification/${sample}.final_wrky_summary.txt" ]] && \
                    classified_count=$(grep -v "^#" "${WORK_DIR}/06.final_classification/${sample}.final_wrky_summary.txt" 2>/dev/null | grep -v "^Gene_ID" | wc -l 2>/dev/null || echo 0)
                
                echo "âœ… ${sample}: HMM=${hmm_count:-0}, CDD=${cdd_count:-0}, Direct=${direct_count:-0}, Final=${final_count:-0}, Classified=${classified_count:-0}"
            fi
        done
        
        echo ""
        echo "ğŸ“ˆ Overall Statistics:"
        echo "---------------------"
        echo "Total samples: ${total_samples:-0}"
        echo "Successful samples: ${successful_samples:-0}"
        echo "Failed samples: ${error_samples:-0}"
        if [[ ${total_samples:-0} -gt 0 ]]; then
            echo "Success rate: $(( (successful_samples * 100) / total_samples ))%"
        else
            echo "Success rate: 0%"
        fi
        
        echo ""
        echo "ğŸ“Š WRKY Classification Summary:"
        echo "------------------------------"
        
        # ç»Ÿè®¡æ‰€æœ‰æ ·å“çš„åˆ†ç±»ç»“æœ
        local total_wrky_genes=0
        local total_group_i=0
        local total_group_ii=0
        local total_group_iii=0
        local total_other=0
        
        for sample in $(get_samples); do
            if ! grep -q "${sample}" "${ERROR_SAMPLE_FILE}" 2>/dev/null; then
                local class_file="${WORK_DIR}/06.final_classification/${sample}.final_wrky_summary.txt"
                if [[ -f "${class_file}" ]]; then
                    local sample_total=$(grep -v "^#" "${class_file}" 2>/dev/null | grep -v "^Gene_ID" | wc -l 2>/dev/null || echo 0)
                    total_wrky_genes=$((total_wrky_genes + ${sample_total:-0}))
                    
                    # ç»Ÿè®¡å„ç»„ - ä½¿ç”¨å®‰å…¨çš„ç®—æœ¯è¿ç®—
                    local group_i=$(grep -v "^#" "${class_file}" 2>/dev/null | grep -v "^Gene_ID" | grep -c "^[^\t]*\tI\t" 2>/dev/null || echo 0)
                    local group_ii=$(grep -v "^#" "${class_file}" 2>/dev/null | grep -v "^Gene_ID" | grep -c "^[^\t]*\tII\t" 2>/dev/null || echo 0)
                    local group_iii=$(grep -v "^#" "${class_file}" 2>/dev/null | grep -v "^Gene_ID" | grep -c "^[^\t]*\tIII\t" 2>/dev/null || echo 0)
                    local other=$(grep -v "^#" "${class_file}" 2>/dev/null | grep -v "^Gene_ID" | grep -c "^[^\t]*\t\(other\|NA\)\t" 2>/dev/null || echo 0)
                    
                    # ä½¿ç”¨å®‰å…¨çš„ç®—æœ¯è¿ç®—
                    total_group_i=$(safe_add "$total_group_i" "$group_i")
                    total_group_ii=$(safe_add "$total_group_ii" "$group_ii")
                    total_group_iii=$(safe_add "$total_group_iii" "$group_iii")
                    total_other=$(safe_add "$total_other" "$other")
                fi
            fi
        done
        
        echo "Total WRKY genes identified: ${total_wrky_genes:-0}"
        echo "Group I: ${total_group_i:-0}"
        echo "Group II: ${total_group_ii:-0}"
        echo "Group III: ${total_group_iii:-0}"
        echo "Other/Unclassified: ${total_other:-0}"
        
        if [[ ${error_samples:-0} -gt 0 ]]; then
            echo ""
            echo "âŒ Failed samples:"
            cat "${ERROR_SAMPLE_FILE}" 2>/dev/null || echo "Error reading error file"
        fi
        
    } > "${SUMMARY_FILE}"
    
    log_info "ğŸ“Š Summary saved to: ${SUMMARY_FILE}"
}

# ğŸš€ Main execution
main() {
    log_info "ğŸ§¬ Starting WRKY analysis pipeline (Serial Mode with Classification)..."
    
    # Get all samples
    samples=($(get_samples))
    log_info "ğŸ“‹ Found ${#samples[@]} samples to process"
    log_info "ğŸ“ Samples: ${samples[*]}"
    
    # Process samples one by one
    local processed=0
    local successful=0
    local failed=0
    
    for sample in "${samples[@]}"; do
        processed=$((processed + 1))
        log_info ""
        log_info "ğŸš€ Processing sample ${processed}/${#samples[@]}: ${sample}"
        
        # Process sample and handle errors gracefully
        if process_sample "${sample}"; then
            successful=$((successful + 1))
            log_info "âœ… Successfully completed ${sample}"
        else
            failed=$((failed + 1))
            log_warn "âš ï¸ Failed to process ${sample}, continuing with next sample..."
        fi
    done
    
    # Generate summary
    generate_summary
    
    log_info ""
    log_info "ğŸ‰ WRKY analysis pipeline completed!"
    log_info "ğŸ“Š Processing summary: ${processed} total, ${successful} successful, ${failed} failed"
    log_info "ğŸ“Š Check results in: ${WORK_DIR}"
    log_info "ğŸ“ˆ Summary: ${SUMMARY_FILE}"
    log_info "ğŸ”¬ WRKY classifications: ${WORK_DIR}/06.final_classification/"
    log_info "â° Analysis finished at: $(date)"
}

# Check dependencies
check_dependencies() {
    log_info "ğŸ” Checking dependencies..."
    
    local missing_deps=()
    
    command -v biopytools >/dev/null 2>&1 || missing_deps+=("biopytools")
    command -v hmmsearch >/dev/null 2>&1 || missing_deps+=("hmmsearch")
    command -v rpsblast >/dev/null 2>&1 || missing_deps+=("rpsblast")
    command -v python3 >/dev/null 2>&1 || missing_deps+=("python3")
    
    if [[ ${#missing_deps[@]} -gt 0 ]]; then
        log_error "âŒ Missing dependencies: ${missing_deps[*]}"
        exit 1
    fi
    
    # Check Python packages
    if ! python3 -c "import Bio" 2>/dev/null; then
        log_error "âŒ Missing Python package: biopython"
        exit 1
    fi
    
    log_info "âœ… All dependencies found"
}

# Run the pipeline
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    # Ensure log directory exists and is writable
    mkdir -p "$(dirname "${LOG_FILE}")"
    
    # Test log file writing
    if ! echo "ğŸ§ª Log test" > "${LOG_FILE}" 2>/dev/null; then
        echo "âŒ Cannot write to log file: ${LOG_FILE}"
        echo "âŒ Current directory: $(pwd)"
        echo "âŒ User: $(whoami)"
        echo "âŒ Permissions: $(ls -la "$(dirname "${LOG_FILE}")" 2>/dev/null || echo 'Directory not accessible')"
        exit 1
    fi
    
    log_info "ğŸš€ Starting WRKY pipeline with classification in serial mode..."
    
    check_dependencies
    main "$@"
fi