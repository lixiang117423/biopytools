2026-01-08 09:45:35.537 - INFO - HapHiC处理器已初始化|HapHiC processor initialized
2026-01-08 09:45:35.537 - INFO - 配置参数|Configuration Parameters:
2026-01-08 09:45:35.537 - INFO -   assembly_file: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary.fa
2026-01-08 09:45:35.537 - INFO -   hic_file: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/01.data/hic/OV53_1-hic_R1.fastq.gz
2026-01-08 09:45:35.537 - INFO -   hic_file_type: fastq
2026-01-08 09:45:35.537 - INFO -   nchrs: 12
2026-01-08 09:45:35.537 - INFO -   output_dir: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2
2026-01-08 09:45:35.537 - INFO -   prefix: OV53_1.hap2.primary
2026-01-08 09:45:35.537 - INFO -   threads: 64
2026-01-08 09:45:35.537 - INFO -   processes: 8
2026-01-08 09:45:35.537 - INFO -   quick_view: False
2026-01-08 09:45:35.537 - INFO -   restriction_sites: ['GATC']
2026-01-08 09:45:35.537 - INFO -   correct_nrounds: 2
2026-01-08 09:45:35.537 - INFO -   remove_allelic_links: None
2026-01-08 09:45:35.537 - INFO -   phasing_weight: 1.0
2026-01-08 09:45:35.537 - INFO -   gfa_files: None
2026-01-08 09:45:35.537 - INFO -   haphic_bin: /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/haphic
2026-01-08 09:45:35.537 - INFO -   bwa_bin: bwa
2026-01-08 09:45:35.537 - INFO -   samtools_bin: samtools
2026-01-08 09:45:35.537 - INFO - 开始HapHiC流程|Starting HapHiC pipeline
2026-01-08 09:45:35.537 - INFO - 系统预检查|System pre-flight checks
2026-01-08 09:45:35.537 - INFO - 验证输入文件|Validating input files
2026-01-08 09:45:36.438 - INFO - 基因组序列数量|Assembly sequence count: 972
2026-01-08 09:45:36.438 - INFO - FASTQ文件大小|FASTQ file sizes: R1 60.14 GB, R2 58.01 GB
2026-01-08 09:45:36.438 - INFO - 输入文件验证通过|Input files validated
2026-01-08 09:45:36.438 - INFO - 检查系统资源|Checking system resources
2026-01-08 09:45:36.691 - INFO - 可用内存|Available memory: 455.4 GB
2026-01-08 09:45:36.691 - INFO - 可用磁盘空间|Available disk space: 1536481.2 GB
2026-01-08 09:45:36.691 - INFO - CPU核心数|CPU cores: 88
2026-01-08 09:45:38.266 - INFO - 预检查通过|Pre-flight checks passed
2026-01-08 09:45:38.266 - INFO - 检查已存在的比对结果|Checking for existing alignment results
2026-01-08 09:45:38.266 - INFO - 输出目录: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2
2026-01-08 09:45:38.266 - INFO - 比对目录: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping
2026-01-08 09:45:38.266 - INFO - 潜在BAM文件: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.bam
2026-01-08 09:45:38.267 - INFO - 潜在过滤BAM文件: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam
2026-01-08 09:45:38.267 - INFO - 比对目录存在|Alignment directory exists
2026-01-08 09:45:38.267 - INFO - 比对目录内容: ['assembly.fa.amb', 'assembly.fa.bwt', 'assembly.fa.ann', 'assembly.fa', 'HiC.filtered.bam', 'assembly.fa.pac', 'read1_1.fastq.gz', 'HiC.bam', 'assembly.fa.sa', 'read2_1.fastq.gz']
2026-01-08 09:45:38.267 - INFO - 发现已存在的过滤BAM文件，跳过BWA比对步骤|Found existing filtered BAM file, skipping BWA alignment: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam (58,021,990,062 bytes)
2026-01-08 09:45:38.267 - INFO - 使用按read name排序的过滤BAM文件以满足HapHiC要求|Using read name-sorted filtered BAM file to meet HapHiC requirements
2026-01-08 09:45:38.268 - INFO -  开始HapHiC Pipeline流程|Starting HapHiC Pipeline
2026-01-08 09:45:38.272 - INFO -  设置目录结构|Setting up directory structure
2026-01-08 09:45:38.272 - INFO -  目录结构设置完成|Directory structure setup complete
2026-01-08 09:45:38.272 - INFO -  检查HapHiC Pipeline完成状态|Checking HapHiC Pipeline completion status
2026-01-08 09:45:38.272 - INFO -  Cluster步骤未完成|Cluster step not completed
2026-01-08 09:45:38.272 - INFO -    期待文件: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/01.cluster/corrected_asm.fa, /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/01.cluster/paired_links.clm
2026-01-08 09:45:38.272 - INFO -  Reassign步骤未完成|Reassign step not completed
2026-01-08 09:45:38.272 - INFO -    期待文件: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/final_clusters.txt
2026-01-08 09:45:38.272 - INFO -  Sort步骤未完成|Sort step not completed
2026-01-08 09:45:38.272 - INFO -    期待文件: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/03.sort/*.tour (0 files)
2026-01-08 09:45:38.272 - INFO -  Build步骤未完成|Build step not completed
2026-01-08 09:45:38.272 - INFO -    期待文件: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/04.build/OV53_1.hap2.primary.fa, /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/04.build/OV53_1.hap2.primary.agp
2026-01-08 09:45:38.273 - INFO -  运行HapHiC Pipeline|Running HapHiC Pipeline
2026-01-08 09:45:38.273 - INFO -  HapHiC将处理已存在的目录|HapHiC will handle existing directories
2026-01-08 09:45:38.273 - INFO -  自动优化分辨率: 500bp (基于覆盖率10.0)
2026-01-08 09:45:38.273 - INFO -  启用组装校正，使用分辨率: 500bp (内存优化)
2026-01-08 09:45:38.273 - INFO -  工作目录: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2
2026-01-08 09:45:38.273 - INFO - HapHiC Pipeline
2026-01-08 10:25:38.882 - INFO - 命令执行成功|Command executed successfully (耗时: 2400.61秒)
2026-01-08 10:25:38.882 - INFO - 命令输出|Command Output:
2026-01-08 09:45:59 <HapHiC_pipeline.py> [main] Pipeline started, HapHiC version: 1.0.7 (update: 2025.05.07)
2026-01-08 09:45:59 <HapHiC_pipeline.py> [main] Python version: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]
2026-01-08 09:45:59 <HapHiC_pipeline.py> [main] Command: /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_pipeline.py /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary.fa /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam 12 --aln_format bam --outdir /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2 --RE GATC --steps 1,2,3,4 --threads 64 --processes 8 --correct_nrounds 2 --correct_resolution 500 --median_cov_ratio 0.2 --region_len_ratio 0.1 --min_region_cutoff 5000 --Nx 80 --RE_site_cutoff 25 --density_lower 0.2X --density_upper 1.9X --read_depth_upper 1.5X --topN 10 --min_inflation 1.0 --max_inflation 3.0 --inflation_step 0.2 --expansion 2 --max_iter 200 --pruning 0.0001 --min_group_len 0 --max_ctg_len 10000 --min_RE_sites 25 --min_links 25 --min_link_density 0.0001 --min_density_ratio 4 --ambiguous_cutoff 0.6 --reassign_nrounds 5 --skip_allhic --mutprob 0.2 --ngen 5000 --npop 100 --seed 42 --Ns 100 --max_width 60 --prefix OV53_1.hap2.primary
2026-01-08 09:45:59 <HapHiC_pipeline.py> [main] The directory /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2 already exists
2026-01-08 09:45:59 <HapHiC_pipeline.py> [haphic_cluster] Step1: Execute preprocessing and Markov clustering for contigs...
2026-01-08 09:45:59 <HapHiC_cluster.py> [run] Program started, HapHiC version: 1.0.7 (update: 2025.05.07)
2026-01-08 09:45:59 <HapHiC_cluster.py> [run] Python version: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]
2026-01-08 09:45:59 <HapHiC_cluster.py> [run] Command: /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_pipeline.py /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary.fa /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam 12 --aln_format bam --outdir /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2 --RE GATC --steps 1,2,3,4 --threads 64 --processes 8 --correct_nrounds 2 --correct_resolution 500 --median_cov_ratio 0.2 --region_len_ratio 0.1 --min_region_cutoff 5000 --Nx 80 --RE_site_cutoff 25 --density_lower 0.2X --density_upper 1.9X --read_depth_upper 1.5X --topN 10 --min_inflation 1.0 --max_inflation 3.0 --inflation_step 0.2 --expansion 2 --max_iter 200 --pruning 0.0001 --min_group_len 0 --max_ctg_len 10000 --min_RE_sites 25 --min_links 25 --min_link_density 0.0001 --min_density_ratio 4 --ambiguous_cutoff 0.6 --reassign_nrounds 5 --skip_allhic --mutprob 0.2 --ngen 5000 --npop 100 --seed 42 --Ns 100 --max_width 60 --prefix OV53_1.hap2.primary
2026-01-08 09:45:59 <HapHiC_cluster.py> [parse_fasta] Parsing input FASTA file...
2026-01-08 09:46:02 <HapHiC_cluster.py> [determine_int_type] The longest and second longest contigs are 26774908 bp and 15667453 bp, respectively. The data types for contig positions and CLM distances are calculated to be int32 and int32, respectively.
2026-01-08 09:46:03 <HapHiC_cluster.py> [parse_bam_for_correction] Parsing input BAM file for contig correction...
2026-01-08 09:46:03 <HapHiC_cluster.py> [check_sorting_order] The sorting order of the BAM file is unsorted
2026-01-08 10:03:02 <HapHiC_cluster.py> [correct_assembly] Performing assembly correction...
2026-01-08 10:03:11 <HapHiC_cluster.py> [correct_assembly] Correction round 1, breakpoints are detected in 13 contig(s)
2026-01-08 10:03:11 <HapHiC_cluster.py> [break_and_update_ctgs] Breaking contigs and updating data...
2026-01-08 10:03:13 <HapHiC_cluster.py> [correct_assembly] Correction round 2, breakpoints are detected in 0 contig(s)
2026-01-08 10:03:13 <HapHiC_cluster.py> [correct_assembly] Generating corrected assembly file...
2026-01-08 10:03:13 <HapHiC_cluster.py> [correct_assembly] 13 contigs were broken into 26 contigs. Writing corrected assembly to corrected_asm.fa...
2026-01-08 10:03:14 <HapHiC_cluster.py> [stat_fragments] Making some statistics of fragments (contigs / bins)
2026-01-08 10:03:14 <HapHiC_cluster.py> [stat_fragments] bin_size is calculated to be 2000000 bp
2026-01-08 10:03:15 <HapHiC_cluster.py> [parse_alignments] Parsing input alignments...
2026-01-08 10:03:15 <HapHiC_cluster.py> [check_sorting_order] The sorting order of the BAM file is unsorted
2026-01-08 10:22:53 <HapHiC_cluster.py> [output_pickle] Writing HT_link_dict to HT_links.pkl...
2026-01-08 10:22:53 <HapHiC_cluster.py> [output_clm] Writing clm_dict to paired_links.clm...
2026-01-08 10:24:43 <HapHiC_cluster.py> [filter_fragments] Filtering fragments...
2026-01-08 10:24:43 <HapHiC_cluster.py> [filter_fragments] [Nx filtering] 560 fragments kept
2026-01-08 10:24:43 <HapHiC_cluster.py> [filter_fragments] [RE sites filtering] 0 fragments removed, 560 fragments kept
2026-01-08 10:24:43 <HapHiC_cluster.py> [filter_fragments] [link density filtering] Parameter --density_lower 0.2X is set to "multiple" mode and equivalent to 0.010714285714285714 in "fraction" mode
2026-01-08 10:24:43 <HapHiC_cluster.py> [filter_fragments] [link density filtering] Parameter --density_upper 1.9X is set to "multiple" mode and equivalent to 0.9892857142857143 in "fraction" mode
2026-01-08 10:24:43 <HapHiC_cluster.py> [filter_fragments] [link density filtering] 12 fragments removed, 548 fragments kept
2026-01-08 10:24:44 <HapHiC_cluster.py> [filter_fragments] [rank sum filtering] Q1=230.0, median=264.0, Q3=301.25, IQR=Q3-Q1=71.25
2026-01-08 10:24:44 <HapHiC_cluster.py> [filter_fragments] [rank sum filtering] Parameter --rank_sum_upper 1.5X is set to "multiple" mode and equivalent to 0.8704379562043796 in "fraction" mode
2026-01-08 10:24:44 <HapHiC_cluster.py> [filter_fragments] [rank sum filtering] 71 fragments removed, 477 fragments kept
2026-01-08 10:24:44 <HapHiC_cluster.py> [output_pickle] Writing full_link_dict to full_links.pkl...
2026-01-08 10:24:44 <HapHiC_cluster.py> [run] Hi-C linking matrix was constructed in 2325.4025774002075s
2026-01-08 10:24:44 <HapHiC_cluster.py> [run_mcl_clustering] Performing Markov clustering...
2026-01-08 10:24:44 <HapHiC_cluster.py> [mcl] The matrix has converged after 6 rounds of iterations (expansion: 2, inflation: 1.0, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:45 <HapHiC_cluster.py> [mcl] The matrix has converged after 35 rounds of iterations (expansion: 2, inflation: 1.2, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:45 <HapHiC_cluster.py> [mcl] The matrix has converged after 17 rounds of iterations (expansion: 2, inflation: 1.4, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:45 <HapHiC_cluster.py> [mcl] The matrix has converged after 13 rounds of iterations (expansion: 2, inflation: 1.6, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:45 <HapHiC_cluster.py> [mcl] The matrix has converged after 14 rounds of iterations (expansion: 2, inflation: 1.8, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:45 <HapHiC_cluster.py> [mcl] The matrix has converged after 18 rounds of iterations (expansion: 2, inflation: 2.0, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:45 <HapHiC_cluster.py> [mcl] The matrix has converged after 14 rounds of iterations (expansion: 2, inflation: 2.2, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:46 <HapHiC_cluster.py> [mcl] The matrix has converged after 15 rounds of iterations (expansion: 2, inflation: 2.4, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:46 <HapHiC_cluster.py> [mcl] The matrix has converged after 10 rounds of iterations (expansion: 2, inflation: 2.6, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:46 <HapHiC_cluster.py> [mcl] The matrix has converged after 12 rounds of iterations (expansion: 2, inflation: 2.8, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:46 <HapHiC_cluster.py> [mcl] The matrix has converged after 10 rounds of iterations (expansion: 2, inflation: 3.0, maximum iterations: 200, pruning threshold: 0.0001)
2026-01-08 10:24:46 <HapHiC_cluster.py> [recommend_inflation] You could try inflation from 2.4 (length ratio = 0.75)
2026-01-08 10:24:46 <HapHiC_cluster.py> [run] 11 round(s) of Markov clustering finished in 1.752037763595581s, average 0.159276160326871s per round
2026-01-08 10:24:46 <HapHiC_cluster.py> [output_statistics] Making some statistics for the next HapHiC reassignment step...
2026-01-08 10:24:58 <HapHiC_cluster.py> [run] Program finished in 2339.7448637485504s
2026-01-08 10:24:59 <HapHiC_pipeline.py> [haphic_reassign] Step2: Reassign and rescue contigs...
2026-01-08 10:24:59 <HapHiC_reassign.py> [run] Program started, HapHiC version: 1.0.7 (update: 2025.05.07)
2026-01-08 10:24:59 <HapHiC_reassign.py> [run] Python version: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]
2026-01-08 10:24:59 <HapHiC_reassign.py> [run] Command: /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_pipeline.py /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary.fa /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam 12 --aln_format bam --outdir /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2 --RE GATC --steps 1,2,3,4 --threads 64 --processes 8 --correct_nrounds 2 --correct_resolution 500 --median_cov_ratio 0.2 --region_len_ratio 0.1 --min_region_cutoff 5000 --Nx 80 --RE_site_cutoff 25 --density_lower 0.2X --density_upper 1.9X --read_depth_upper 1.5X --topN 10 --min_inflation 1.0 --max_inflation 3.0 --inflation_step 0.2 --expansion 2 --max_iter 200 --pruning 0.0001 --min_group_len 0 --max_ctg_len 10000 --min_RE_sites 25 --min_links 25 --min_link_density 0.0001 --min_density_ratio 4 --ambiguous_cutoff 0.6 --reassign_nrounds 5 --skip_allhic --mutprob 0.2 --ngen 5000 --npop 100 --seed 42 --Ns 100 --max_width 60 --prefix OV53_1.hap2.primary
2026-01-08 10:24:59 <HapHiC_cluster.py> [parse_fasta] Parsing input FASTA file...
2026-01-08 10:25:02 <HapHiC_cluster.py> [determine_int_type] The longest and second longest contigs are 26774908 bp and 15667453 bp, respectively. The data types for contig positions and CLM distances are calculated to be int32 and int32, respectively.
2026-01-08 10:25:02 <HapHiC_reassign.py> [parse_pickle] Parsing input pickle file...
2026-01-08 10:25:03 <HapHiC_reassign.py> [parse_clusters] Parsing .clusters.txt file...
2026-01-08 10:25:03 <HapHiC_reassign.py> [run] File parsing and data preparation finished in 4.284264326095581s
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] Performing reassignment...
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] [result::round1] Total: 985, consistent: 244, rescued: 465, reassigned: 7, not rescued: 269
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] Performing reassignment...
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] [result::round2] Total: 985, consistent: 721, rescued: 24, reassigned: 1, not rescued: 239
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] Performing reassignment...
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] [result::round3] Total: 985, consistent: 748, rescued: 7, reassigned: 0, not rescued: 230
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] Performing reassignment...
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] [result::round4] Total: 985, consistent: 753, rescued: 0, reassigned: 0, not rescued: 232
2026-01-08 10:25:03 <HapHiC_reassign.py> [run] [result::round4] Result has converged after 3 rounds of reassignment, break
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] Performing additional round of rescue...
2026-01-08 10:25:03 <HapHiC_reassign.py> [run_reassignment] [result::additional_rescue] Total: 985, consistent: 805, rescued: 46, reassigned: 0, not rescued: 134
2026-01-08 10:25:03 <HapHiC_reassign.py> [run] 4 round(s) of reassignment finished in 0.3350203037261963s, average 0.08375507593154907s per round
2026-01-08 10:25:03 <HapHiC_reassign.py> [agglomerative_hierarchical_clustering] Performing additional agglomerative hierarchical clustering...
2026-01-08 10:25:03 <HapHiC_reassign.py> [agglomerative_hierarchical_clustering] The parameter "affinity" is not found in AgglomerativeClustering, use "metric" instead
2026-01-08 10:25:03 <HapHiC_reassign.py> [split_clm_file] Splitting clm file into subfiles by group...
2026-01-08 10:25:25 <HapHiC_reassign.py> [run] Program finished in 26.419026613235474s
2026-01-08 10:25:25 <HapHiC_pipeline.py> [haphic_sort] Step3: Order and orient contigs within each group...
2026-01-08 10:25:27 <HapHiC_sort.py> [run] Program started, HapHiC version: 1.0.7 (update: 2025.05.07)
2026-01-08 10:25:27 <HapHiC_sort.py> [run] Python version: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]
2026-01-08 10:25:27 <HapHiC_sort.py> [run] Command: /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_sort.py /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/01.cluster/corrected_asm.fa /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/01.cluster/HT_links.pkl /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/split_clms /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group2_107131539bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group3_98984222bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group6_94728423bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group5_96054017bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group10_84134193bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group9_86700226bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group4_98662327bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group12_57817578bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group11_75756093bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group7_92810332bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group1_118337314bp.txt /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/02.reassign/final_groups/group8_90014918bp.txt --skip_allhic --mutprob 0.2 --ngen 5000 --npop 100 --seed 42 --processes 8 --flanking_region 0 --density_cal_method multiplication --confidence_cutoff 1
2026-01-08 10:25:27 <HapHiC_sort.py> [run] Checking the path of ALLHiC...
2026-01-08 10:25:27 <HapHiC_sort.py> [run] ALLHiC has been found in /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts
2026-01-08 10:25:27 <HapHiC_sort.py> [parse_fasta] Parsing fasta file...
2026-01-08 10:25:28 <HapHiC_sort.py> [run] Loading input pickle file...
2026-01-08 10:25:29 <HapHiC_sort.py> [run] Parsing group files and clm files...
2026-01-08 10:25:29 <HapHiC_sort.py> [run] Program will be executed in multiprocessing mode (processes=8)
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group2_107131539bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group2_107131539bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group2_107131539bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group6_94728423bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group6_94728423bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group6_94728423bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group5_96054017bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group10_84134193bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group10_84134193bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group5_96054017bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group10_84134193bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group5_96054017bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group3_98984222bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group3_98984222bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group3_98984222bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group9_86700226bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group9_86700226bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group9_86700226bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group12_57817578bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group12_57817578bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group12_57817578bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group4_98662327bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group4_98662327bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group4_98662327bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group11_75756093bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group11_75756093bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group11_75756093bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group7_92810332bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group7_92810332bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group7_92810332bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group1_118337314bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group1_118337314bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group1_118337314bp] Starting fast sorting iterations...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group8_90014918bp] Performing fast sorting...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group8_90014918bp] Checking the content of input group file...
2026-01-08 10:25:29 <HapHiC_sort.py> [fast_sort] [group8_90014918bp] Starting fast sorting iterations...
2026-01-08 10:25:30 <HapHiC_sort.py> [run] Program finished in 2.5000154972076416s
2026-01-08 10:25:30 <HapHiC_pipeline.py> [haphic_build] Step4: Build final scaffolds (pseudomolecules)...
2026-01-08 10:25:30 <HapHiC_build.py> [run] Program started, HapHiC version: 1.0.7 (update: 2025.05.07)
2026-01-08 10:25:30 <HapHiC_build.py> [run] Python version: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]
2026-01-08 10:25:30 <HapHiC_build.py> [run] Command: /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_pipeline.py /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary.fa /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam 12 --aln_format bam --outdir /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2 --RE GATC --steps 1,2,3,4 --threads 64 --processes 8 --correct_nrounds 2 --correct_resolution 500 --median_cov_ratio 0.2 --region_len_ratio 0.1 --min_region_cutoff 5000 --Nx 80 --RE_site_cutoff 25 --density_lower 0.2X --density_upper 1.9X --read_depth_upper 1.5X --topN 10 --min_inflation 1.0 --max_inflation 3.0 --inflation_step 0.2 --expansion 2 --max_iter 200 --pruning 0.0001 --min_group_len 0 --max_ctg_len 10000 --min_RE_sites 25 --min_links 25 --min_link_density 0.0001 --min_density_ratio 4 --ambiguous_cutoff 0.6 --reassign_nrounds 5 --skip_allhic --mutprob 0.2 --ngen 5000 --npop 100 --seed 42 --Ns 100 --max_width 60 --prefix OV53_1.hap2.primary
2026-01-08 10:25:30 <HapHiC_cluster.py> [parse_fasta] Parsing input FASTA file...
2026-01-08 10:25:33 <HapHiC_build.py> [parse_tours] Parsing tour files...
2026-01-08 10:25:33 <HapHiC_build.py> [build_final_scaffolds] Building final scaffolds...
2026-01-08 10:25:38 <HapHiC_build.py> [run] Program finished in 8.473069667816162s
2026-01-08 10:25:38 <HapHiC_pipeline.py> [main] HapHiC pipeline finished in 2379.442280292511s
2026-01-08 10:25:38.882 - INFO -  验证Pipeline输出|Verifying pipeline output
2026-01-08 10:25:38.882 - WARNING -  corrected_asm不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary_corrected.asm.fa
2026-01-08 10:25:38.882 - WARNING -  scaffolds_agp不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary_scaffolds.agp
2026-01-08 10:25:38.882 - WARNING -  scaffolds_raw_agp不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary_scaffolds.raw.agp
2026-01-08 10:25:38.882 - WARNING -  scaffolds_fasta不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary_scaffolds.fa
2026-01-08 10:25:38.883 - WARNING -  juicebox_script不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary_juicebox.sh
2026-01-08 10:25:38.883 - WARNING -  contact_map不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary_contact_map.pdf
2026-01-08 10:25:38.883 - WARNING -  hic_file不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/06.juicebox/OV53_1.hap2.primary.hic
2026-01-08 10:25:38.883 - WARNING -  assembly_file不存在: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/06.juicebox/OV53_1.hap2.primary.assembly
2026-01-08 10:25:38.883 - INFO -  log_file: OV53_1.hap2.primary_haphic.log (31,804 bytes)
2026-01-08 10:25:38.883 - INFO -  生成Hi-C接触图可视化|Generating Hi-C contact map visualization
2026-01-08 10:25:38.883 - INFO -  使用Raw AGP文件（格式更标准）: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/04.build/OV53_1.hap2.primary.raw.agp
2026-01-08 10:25:38.884 - INFO -  AGP文件预处理完成: 共 1824 行，跳过 0 行，输出到 /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/04.build/OV53_1.hap2.primary.raw.processed.agp
2026-01-08 10:25:38.885 - INFO - 生成可视化
2026-01-08 10:25:39.432 - ERROR - 命令执行失败|Command failed (返回码: 1)
2026-01-08 10:25:39.432 - ERROR - 命令输出|Command Output:
2026-01-08 10:25:39 <HapHiC_plot.py> [main] Program started, HapHiC version: 1.0.7 (update: 2025.05.07)
2026-01-08 10:25:39 <HapHiC_plot.py> [main] Python version: 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]
2026-01-08 10:25:39 <HapHiC_plot.py> [main] Command: /share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_plot.py /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary.fa /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/04.build/OV53_1.hap2.primary.raw.processed.agp --bin_size 500 --min_len 1
2026-01-08 10:25:39 <HapHiC_plot.py> [parse_agp] Parsing input AGP file...
Traceback (most recent call last):
  File "/share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_plot.py", line 840, in <module>
    main()
  File "/share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_plot.py", line 808, in main
    ctg_dict, ctg_aln_dict, group_size_dict, frag_set, group_frag_dict = parse_agp(args.agp, bin_size)
                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_plot.py", line 60, in parse_agp
    if cols[4] == 'W':
       ~~~~^^^
IndexError: list index out of range
Traceback (most recent call last):
  File "/share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/haphic", line 117, in <module>
    subprocess.run(commands, check=True)
  File "/share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['/share/org/YZWL/yzwl_lixg/miniforge3/envs/haphic/bin/scripts/HapHiC_plot.py', '/share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/OV53_1.hap2.primary.fa', '/share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/04.build/OV53_1.hap2.primary.raw.processed.agp', '--bin_size', '500', '--min_len', '1']' returned non-zero exit status 1.
2026-01-08 10:25:39.432 - WARNING -  可视化生成失败，但继续执行其他步骤|Visualization failed, but continuing with other steps
2026-01-08 10:25:39.432 - INFO -  生成Juicebox文件|Generating Juicebox files
2026-01-08 10:25:39.432 - INFO -  Juicebox目录: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/06.juicebox
2026-01-08 10:25:39.432 - INFO -  使用Raw AGP文件（格式更标准）: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/04.build/OV53_1.hap2.primary.raw.agp
2026-01-08 10:25:39.432 - INFO -  步骤1: 使用matlock生成.mnd文件|Step 1: Generate .mnd file with matlock
2026-01-08 10:25:39.432 - INFO - 生成.mnd文件
2026-01-08 10:39:40.298 - INFO - 命令执行成功|Command executed successfully (耗时: 840.87秒)
2026-01-08 10:39:40.298 - INFO - 命令输出|Command Output:
INFO: converting bam to juicer on /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam
INFO: detected bam filetype
INFO: reading file "/share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/00.mapping/HiC.filtered.bam"
INFO: parsed 1000000 read pairs
INFO: parsed 2000000 read pairs
INFO: parsed 3000000 read pairs
INFO: parsed 4000000 read pairs
INFO: parsed 5000000 read pairs
INFO: parsed 6000000 read pairs
INFO: parsed 7000000 read pairs
INFO: parsed 8000000 read pairs
INFO: parsed 9000000 read pairs
INFO: parsed 10000000 read pairs
INFO: parsed 11000000 read pairs
INFO: parsed 12000000 read pairs
INFO: parsed 13000000 read pairs
INFO: parsed 14000000 read pairs
INFO: parsed 15000000 read pairs
INFO: parsed 16000000 read pairs
INFO: parsed 17000000 read pairs
INFO: parsed 18000000 read pairs
INFO: parsed 19000000 read pairs
INFO: parsed 20000000 read pairs
INFO: parsed 21000000 read pairs
INFO: parsed 22000000 read pairs
INFO: parsed 23000000 read pairs
INFO: parsed 24000000 read pairs
INFO: parsed 25000000 read pairs
INFO: parsed 26000000 read pairs
INFO: parsed 27000000 read pairs
INFO: parsed 28000000 read pairs
INFO: parsed 29000000 read pairs
INFO: parsed 30000000 read pairs
INFO: parsed 31000000 read pairs
INFO: parsed 32000000 read pairs
INFO: parsed 33000000 read pairs
INFO: parsed 34000000 read pairs
INFO: parsed 35000000 read pairs
INFO: parsed 36000000 read pairs
INFO: parsed 37000000 read pairs
INFO: parsed 38000000 read pairs
INFO: parsed 39000000 read pairs
INFO: parsed 40000000 read pairs
INFO: parsed 41000000 read pairs
INFO: parsed 42000000 read pairs
INFO: parsed 43000000 read pairs
INFO: parsed 44000000 read pairs
INFO: parsed 45000000 read pairs
INFO: parsed 46000000 read pairs
INFO: parsed 47000000 read pairs
INFO: parsed 48000000 read pairs
INFO: parsed 49000000 read pairs
INFO: parsed 50000000 read pairs
INFO: parsed 51000000 read pairs
INFO: parsed 52000000 read pairs
INFO: parsed 53000000 read pairs
INFO: parsed 54000000 read pairs
INFO: parsed 55000000 read pairs
INFO: parsed 56000000 read pairs
INFO: parsed 57000000 read pairs
INFO: parsed 58000000 read pairs
INFO: parsed 59000000 read pairs
INFO: parsed 60000000 read pairs
INFO: parsed 61000000 read pairs
INFO: parsed 62000000 read pairs
INFO: parsed 63000000 read pairs
INFO: parsed 64000000 read pairs
INFO: parsed 65000000 read pairs
INFO: parsed 66000000 read pairs
INFO: parsed 67000000 read pairs
INFO: parsed 68000000 read pairs
INFO: parsed 69000000 read pairs
INFO: parsed 70000000 read pairs
INFO: parsed 71000000 read pairs
INFO: parsed 72000000 read pairs
INFO: parsed 73000000 read pairs
INFO: parsed 74000000 read pairs
INFO: parsed 75000000 read pairs
INFO: parsed 76000000 read pairs
INFO: parsed 77000000 read pairs
INFO: parsed 78000000 read pairs
INFO: parsed 79000000 read pairs
INFO: parsed 80000000 read pairs
INFO: parsed 81000000 read pairs
INFO: parsed 82000000 read pairs
INFO: parsed 83000000 read pairs
INFO: parsed 84000000 read pairs
INFO: parsed 85000000 read pairs
INFO: parsed 86000000 read pairs
INFO: parsed 87000000 read pairs
INFO: parsed 88000000 read pairs
INFO: parsed 89000000 read pairs
INFO: parsed 90000000 read pairs
INFO: parsed 91000000 read pairs
INFO: parsed 92000000 read pairs
INFO: parsed 93000000 read pairs
INFO: parsed 94000000 read pairs
INFO: parsed 95000000 read pairs
INFO: parsed 96000000 read pairs
INFO: parsed 97000000 read pairs
INFO: parsed 98000000 read pairs
INFO: parsed 99000000 read pairs
INFO: parsed 100000000 read pairs
INFO: parsed 101000000 read pairs
INFO: parsed 102000000 read pairs
INFO: parsed 103000000 read pairs
INFO: parsed 104000000 read pairs
INFO: parsed 105000000 read pairs
INFO: parsed 106000000 read pairs
INFO: parsed 107000000 read pairs
INFO: parsed 108000000 read pairs
INFO: parsed 109000000 read pairs
INFO: parsed 110000000 read pairs
INFO: parsed 111000000 read pairs
INFO: parsed 112000000 read pairs
INFO: parsed 113000000 read pairs
INFO: parsed 114000000 read pairs
INFO: parsed 115000000 read pairs
INFO: parsed 116000000 read pairs
INFO: parsed 117000000 read pairs
INFO: parsed 118000000 read pairs
INFO: parsed 119000000 read pairs
INFO: parsed 120000000 read pairs
INFO: parsed 121000000 read pairs
INFO: parsed 122000000 read pairs
INFO: parsed 123000000 read pairs
INFO: parsed 124000000 read pairs
INFO: parsed 125000000 read pairs
INFO: parsed 126000000 read pairs
INFO: parsed 127000000 read pairs
INFO: parsed 128000000 read pairs
INFO: parsed 129000000 read pairs
INFO: parsed 130000000 read pairs
INFO: parsed 131000000 read pairs
INFO: parsed 132000000 read pairs
INFO: parsed 133000000 read pairs
INFO: parsed 134000000 read pairs
INFO: parsed 135000000 read pairs
INFO: parsed 136000000 read pairs
INFO: parsed 137000000 read pairs
INFO: parsed 138000000 read pairs
INFO: parsed 139000000 read pairs
INFO: parsed 140000000 read pairs
INFO: parsed 141000000 read pairs
INFO: parsed 142000000 read pairs
INFO: parsed 143000000 read pairs
INFO: parsed 144000000 read pairs
INFO: parsed 145000000 read pairs
INFO: parsed 146000000 read pairs
INFO: parsed 147000000 read pairs
INFO: parsed 148000000 read pairs
INFO: parsed 149000000 read pairs
INFO: parsed 150000000 read pairs
INFO: parsed 151000000 read pairs
INFO: parsed 152000000 read pairs
INFO: parsed 153000000 read pairs
INFO: parsed 154000000 read pairs
INFO: parsed 155000000 read pairs
INFO: parsed 156000000 read pairs
INFO: parsed 157000000 read pairs
INFO: parsed 158000000 read pairs
INFO: parsed 159000000 read pairs
INFO: parsed 160000000 read pairs
INFO: parsed 161000000 read pairs
INFO: parsed 162000000 read pairs
INFO: parsed 163000000 read pairs
INFO: parsed 164000000 read pairs
INFO: parsed 165000000 read pairs
INFO: parsed 166000000 read pairs
INFO: parsed 167000000 read pairs
INFO: parsed 168000000 read pairs
INFO: parsed 169000000 read pairs
INFO: parsed 170000000 read pairs
INFO: parsed 171000000 read pairs
INFO: parsed 172000000 read pairs
INFO: parsed 173000000 read pairs
INFO: parsed 174000000 read pairs
INFO: parsed 175000000 read pairs
INFO: parsed 176000000 read pairs
INFO: parsed 177000000 read pairs
INFO: parsed 178000000 read pairs
INFO: parsed 179000000 read pairs
INFO: parsed 180000000 read pairs
INFO: parsed 181000000 read pairs
INFO: parsed 182000000 read pairs
INFO: parsed 183000000 read pairs
INFO: parsed 184000000 read pairs
INFO: parsed 185000000 read pairs
INFO: parsed 186000000 read pairs
INFO: parsed 187000000 read pairs
INFO: parsed 188000000 read pairs
INFO: parsed 189000000 read pairs
INFO: parsed 190000000 read pairs
INFO: parsed 191000000 read pairs
INFO: parsed 192000000 read pairs
INFO: parsed 193000000 read pairs
INFO: parsed 194000000 read pairs
INFO: parsed 195000000 read pairs
INFO: parsed 196000000 read pairs
INFO: parsed 197000000 read pairs
INFO: parsed 198000000 read pairs
INFO: parsed 199000000 read pairs
INFO: parsed 200000000 read pairs
INFO: parsed 201000000 read pairs
INFO: parsed 202000000 read pairs
INFO: parsed 203000000 read pairs
INFO: parsed 204000000 read pairs
INFO: parsed 205000000 read pairs
INFO: parsed 206000000 read pairs
INFO: parsed 207000000 read pairs
INFO: parsed 208000000 read pairs
INFO: parsed 209000000 read pairs
INFO: parsed 210000000 read pairs
INFO: parsed 211000000 read pairs
INFO: parsed 212000000 read pairs
INFO: parsed 213000000 read pairs
INFO: parsed 214000000 read pairs
INFO: parsed 215000000 read pairs
INFO: parsed 216000000 read pairs
INFO: parsed 217000000 read pairs
INFO: parsed 218000000 read pairs
INFO: parsed 219000000 read pairs
INFO: parsed 220000000 read pairs
INFO: parsed 221000000 read pairs
INFO: parsed 222000000 read pairs
INFO: parsed 223000000 read pairs
INFO: parsed 224000000 read pairs
INFO: parsed 225000000 read pairs
INFO: parsed 226000000 read pairs
INFO: parsed 227000000 read pairs
INFO: parsed 228000000 read pairs
INFO: parsed 229000000 read pairs
INFO: parsed 230000000 read pairs
INFO: parsed 231000000 read pairs
INFO: parsed 232000000 read pairs
INFO: parsed 233000000 read pairs
INFO: parsed 234000000 read pairs
INFO: parsed 235000000 read pairs
INFO: parsed 236000000 read pairs
INFO: parsed 237000000 read pairs
INFO: parsed 238000000 read pairs
INFO: parsed 239000000 read pairs
INFO: parsed 240000000 read pairs
INFO: parsed 241000000 read pairs
INFO: parsed 242000000 read pairs
INFO: parsed 243000000 read pairs
INFO: parsed 244000000 read pairs
INFO: parsed 245000000 read pairs
INFO: parsed 246000000 read pairs
INFO: parsed 247000000 read pairs
INFO: parsed 248000000 read pairs
INFO: parsed 249000000 read pairs
INFO: parsed 250000000 read pairs
INFO: parsed 251000000 read pairs
INFO: parsed 252000000 read pairs
INFO: parsed 253000000 read pairs
INFO: parsed 254000000 read pairs
INFO: parsed 255000000 read pairs
INFO: parsed 256000000 read pairs
INFO: parsed 257000000 read pairs
INFO: parsed 258000000 read pairs
INFO: parsed 259000000 read pairs
INFO: parsed 260000000 read pairs
INFO: parsed 261000000 read pairs
INFO: parsed 262000000 read pairs
INFO: parsed 263000000 read pairs
INFO: parsed 264000000 read pairs
INFO: parsed 265000000 read pairs
INFO: parsed 266000000 read pairs
INFO: parsed 267000000 read pairs
INFO: parsed 268000000 read pairs
2026-01-08 10:39:40.298 - INFO -  步骤2: 排序.mnd文件|Step 2: Sorting .mnd file
2026-01-08 10:59:05.727 - INFO -  步骤3: 生成.assembly文件|Step 3: Generate .assembly file
2026-01-08 10:59:05.727 - INFO - 生成assembly文件
2026-01-08 10:59:05.874 - INFO - 命令执行成功|Command executed successfully (耗时: 0.15秒)
2026-01-08 10:59:05.874 - INFO -  步骤4: 生成.hic文件|Step 4: Generate .hic file
2026-01-08 10:59:05.874 - INFO - 生成.hic文件
2026-01-08 10:59:05.876 - ERROR - 命令执行失败|Command failed (返回码: 127)
2026-01-08 10:59:05.876 - ERROR - 命令输出|Command Output:
bash: ~/software/3d-dna/visualize/run-asm-visualizer.sh: No such file or directory
2026-01-08 10:59:05.876 - WARNING -  Juicebox文件生成失败，但继续执行其他步骤|Juicebox file generation failed, but continuing with other steps
2026-01-08 10:59:05.876 - INFO -  HapHiC Pipeline完成|HapHiC Pipeline completed in 4407.60秒
2026-01-08 10:59:05.876 - INFO - 检测到纠错后的contig，需要重新比对Hi-C数据|Detected corrected contigs, need to realign Hi-C data
2026-01-08 10:59:05.876 - INFO - 创建纠错流程目录|Creating corrected workflow directory: /share/org/YZWL/yzwl_lixg/project/06.longliuxing_BSA/68.三代数据组装和注释/43.单倍型挂载/hap2/07.corrected_contig_haphic
2026-01-08 10:59:05.876 - INFO - 开始重新比对Hi-C数据到纠错后的组装|Starting Hi-C realignment to corrected assembly
2026-01-08 10:59:05.876 - INFO -  开始BWA比对|Starting BWA alignment (official method)
2026-01-08 10:59:05.876 - INFO -  使用纠错后重新比对目录|Using corrected realignment directory
2026-01-08 10:59:05.877 - INFO -  使用提供的FASTQ文件对|Using provided FASTQ pair: OV53_1-hic_R1.fastq.gz
2026-01-08 10:59:05.877 - INFO -  找到 1 对FASTQ文件|Found 1 FASTQ pairs
2026-01-08 10:59:05.877 - INFO -  创建基因组软链接|Created assembly symlink: assembly.fa
2026-01-08 10:59:05.877 - INFO -  创建FASTQ软链接|Created FASTQ symlinks: read1_1.fastq.gz, read2_1.fastq.gz
2026-01-08 10:59:05.877 - INFO -  创建BWA索引|Creating BWA index: assembly.fa
2026-01-08 11:14:48.078 - INFO -  BWA索引创建完成|BWA index created
2026-01-08 11:14:48.078 - INFO -  步骤1: BWA比对 + 去重 + 初步过滤 (使用 64 线程)|Step 1: BWA alignment + deduplication + initial filtering (using 64 threads)
2026-01-08 11:14:48.078 - INFO -  创建纠错后的BAM文件|Creating corrected BAM file
2026-01-08 11:14:48.078 - INFO -  执行BWA比对管道|Executing BWA alignment pipeline
